{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eaa6dcc-49b3-44fe-84d9-fed1a3a06a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244e60cb-3480-4209-99d9-adc7fcaa888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cap = cv2.CascadeClassifier(\"C:/Users/biswa/AppData/Local/Programs/Python/Python313/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "video_cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, video_data = video_cap.read() \n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "    gray = cv2.cvtColor(video_data, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cap.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(video_data, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Video_live\", video_data)\n",
    "    \n",
    "    if cv2.waitKey(10) == ord(\"a\"):\n",
    "        break\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a79642-0207-44a1-8d24-df3e7b2b36c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"C:/Users/biswa/PROJECT/Gender detectio/age_net.caffemodel\" in function 'cv::dnn::ReadProtoFromBinaryFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Load models\u001b[39;00m\n\u001b[0;32m     38\u001b[0m facenet \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(faceproto, facemodel)\n\u001b[1;32m---> 39\u001b[0m agenet \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(ageproto, agemodel)\n\u001b[0;32m     40\u001b[0m gendernet \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mreadNet(genderproto, gendermodel)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Start video capture\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1138: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"C:/Users/biswa/PROJECT/Gender detectio/age_net.caffemodel\" in function 'cv::dnn::ReadProtoFromBinaryFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def facebox(facenet, frame):\n",
    "    framewidth = frame.shape[1]\n",
    "    frameheight = frame.shape[0]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (277, 277), [104, 117, 123], swapRB=False)\n",
    "    facenet.setInput(blob)\n",
    "    detection = facenet.forward()\n",
    "    bbox = []\n",
    "    print(detection.shape)\n",
    "    for i in range(detection.shape[2]):\n",
    "        confidence = detection[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            x1 = int(detection[0, 0, i, 3] * framewidth)\n",
    "            y1 = int(detection[0, 0, i, 4] * frameheight)\n",
    "            x2 = int(detection[0, 0, i, 5] * framewidth)\n",
    "            y2 = int(detection[0, 0, i, 6] * frameheight)\n",
    "            bbox.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    return frame, bbox\n",
    "\n",
    "\n",
    "\n",
    "faceproto =\"C:/Users/biswa/PROJECT/Gender detection/opencv_face_detector.pbtxt\"\n",
    "facemodel =\"C:/Users/biswa/PROJECT/Gender detection/opencv_face_detector_uint8.pb\"\n",
    "ageproto=\"C:/Users/biswa/PROJECT/Gender detection/age_deploy.prototxt\"\n",
    "agemodel=\"C:/Users/biswa/PROJECT/Gender detectio/age_net.caffemodel\"\n",
    "genderproto=\"C:/sers/biswa/PROJECT/Gender detection/gender_deploy.prototxt\"\n",
    "gendermodel=\"C:/Users/biswa/PROJECT/Gender detection/gender_net.caffemodel\"\n",
    "\n",
    "\n",
    "MODE_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "agelist = ['(0-2)', '(3-5)', '(6-8)', '(9-11)', '(12-14)', '(15-20)', '(20-32)', '(38-43)', '(48-50)', '(52-98)', '(99-100)']\n",
    "genderlist = ['Male', 'Female']\n",
    "\n",
    "\n",
    "facenet = cv2.dnn.readNet(faceproto, facemodel)\n",
    "agenet = cv2.dnn.readNet(ageproto, agemodel)\n",
    "gendernet = cv2.dnn.readNet(genderproto, gendermodel)\n",
    "\n",
    "\n",
    "video_cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = video_cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read from camera.\")\n",
    "        break\n",
    "    \n",
    "    framenet, bbox = facebox(facenet, frame)\n",
    "    for box in bbox:\n",
    "        face = frame[box[1]:box[3], box[0]:box[2]]\n",
    "        if face.size == 0:\n",
    "            continue  \n",
    "\n",
    "        \n",
    "        face_resized = cv2.resize(face, (227, 227))\n",
    "        blob = cv2.dnn.blobFromImage(face_resized, 1.0, (227, 227), MODE_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "        \n",
    "        gendernet.setInput(blob)\n",
    "        gender_pred = gendernet.forward()\n",
    "        gender = genderlist[gender_pred[0].argmax()]\n",
    "\n",
    "        \n",
    "        agenet.setInput(blob)\n",
    "        age_pred = agenet.forward()\n",
    "        age = agelist[age_pred[0].argmax()]\n",
    "\n",
    "    \n",
    "        label = \"{}.{}\".format(gender, age)\n",
    "        cv2.putText(frame, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.2, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Age-Gender Detection\", frame)\n",
    "    if cv2.waitKey(10) == ord(\"a\"):\n",
    "        break\n",
    "        \n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ae66f-69a0-45a6-9352-e013bb55830d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
